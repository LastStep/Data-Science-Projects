{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://vis-www.cs.umass.edu/lfw/number_11.html')\n",
    "soup = bs(r.text, 'html.parser')\n",
    "soup_images = soup.find_all('img', attrs={'alt': 'person image'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = []\n",
    "for person in soup_images:\n",
    "    person_name = person['src'].split('/')[-2]\n",
    "    persons.append(person_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(url):\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.text, 'html.parser')\n",
    "    images = soup.find_all('img', attrs={'alt': lambda x: x and x.startswith('Original image')})\n",
    "    image_urls = [\"http://vis-www.cs.umass.edu/lfw\" + i['src'][2:] for i in images]\n",
    "    return image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, path):\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(path, 'wb') as f:\n",
    "            for chunk in r.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        \n",
    "def save_images(person_name, images, folder='downloads'):\n",
    "    for image_url in images:\n",
    "        image_name = image_url.split('/')[-1]\n",
    "        image_folder = f\"{folder}\\\\{person_name}\"\n",
    "        if not os.path.exists(image_folder):\n",
    "            os.makedirs(image_folder)\n",
    "        image_path = image_folder + f'\\\\{image_name}'\n",
    "        download_image(image_url, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images(images):\n",
    "    total_images = len(images)\n",
    "    split_val = math.floor(.8 * total_images)\n",
    "    training_images = images[:split_val]\n",
    "    testing_images = images[split_val:]\n",
    "    return training_images, testing_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on David_Beckham\n",
      "Images found: 31\n",
      "Working on John_Negroponte\n",
      "Images found: 31\n",
      "Working on Kofi_Annan\n",
      "Images found: 32\n",
      "Working on Roh_Moo-hyun\n",
      "Images found: 32\n",
      "Working on Vicente_Fox\n",
      "Images found: 32\n",
      "Working on Megawati_Sukarnoputri\n",
      "Images found: 33\n",
      "Working on Silvio_Berlusconi\n",
      "Images found: 33\n",
      "Working on Tom_Ridge\n",
      "Images found: 33\n",
      "Working on Alvaro_Uribe\n",
      "Images found: 35\n",
      "Working on Andre_Agassi\n",
      "Images found: 36\n",
      "Working on Nestor_Kirchner\n",
      "Images found: 37\n",
      "Working on Alejandro_Toledo\n",
      "Images found: 39\n",
      "Working on Hans_Blix\n",
      "Images found: 39\n",
      "Working on Laura_Bush\n",
      "Images found: 41\n",
      "Working on Lleyton_Hewitt\n",
      "Images found: 41\n",
      "Working on Arnold_Schwarzenegger\n",
      "Images found: 42\n",
      "Working on Jennifer_Capriati\n",
      "Images found: 42\n",
      "Working on Gloria_Macapagal_Arroyo\n",
      "Images found: 44\n",
      "Working on Luiz_Inacio_Lula_da_Silva\n",
      "Images found: 48\n",
      "Working on Vladimir_Putin\n",
      "Images found: 49\n",
      "Working on Jacques_Chirac\n",
      "Images found: 52\n",
      "Working on Serena_Williams\n",
      "Images found: 52\n",
      "Working on John_Ashcroft\n",
      "Images found: 53\n",
      "Working on Jean_Chretien\n",
      "Images found: 55\n",
      "Working on Junichiro_Koizumi\n",
      "Images found: 60\n",
      "Working on Hugo_Chavez\n",
      "Images found: 71\n",
      "Working on Ariel_Sharon\n",
      "Images found: 77\n",
      "Finished downloading images\n"
     ]
    }
   ],
   "source": [
    "base_link = \"http://vis-www.cs.umass.edu/lfw/person/{}.html\"\n",
    "for person in persons:\n",
    "    person_link = base_link.format(person)\n",
    "    images = get_images(person_link)\n",
    "    if 100 > len(images) > 30:\n",
    "        print(f\"Working on {person}\")\n",
    "        print(f\"Images found: {len(images)}\")\n",
    "        train, test = split_images(images)\n",
    "        save_images(person, images)\n",
    "        save_images(person, train, folder='training')\n",
    "        save_images(person, test, folder='testing')\n",
    "print(\"Finished downloading images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
