{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from google_sheets_api.ipynb\n",
      "Script already ran today, not creating a new spreadsheet\n",
      "Spreadsheet ID: 1RUyuA6JVs7GiG_avmgMHMNJzp2tNs5afUlHsfBVG3k8\n",
      "https://docs.google.com/spreadsheets/d/1RUyuA6JVs7GiG_avmgMHMNJzp2tNs5afUlHsfBVG3k8\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import numpy as np\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import import_ipynb\n",
    "import google_sheets_api as gpi\n",
    "\n",
    "import pickle\n",
    "model = pickle.loads(open('facenet_model', \"rb\").read())\n",
    "\n",
    "dataset_folder = 'Celebrity Faces Dataset'\n",
    "facenet_model = load_model('keras-facenet/model/facenet_keras.h5', compile=False)\n",
    "face_cascade = cv2.CascadeClassifier('Cascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "data = load('celebrity-faces-embeddings.npz')\n",
    "labels = data['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "    \n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "\t# load image from file\n",
    "\timage = Image.open(filename)\n",
    "\t# convert to RGB, if needed\n",
    "\timage = image.convert('RGB')\n",
    "\t# convert to array\n",
    "\tpixels = asarray(image)\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\t# bug fix\n",
    "\tx1, y1 = abs(x1), abs(y1)\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "\t# scale pixel values\n",
    "\tface_pixels = face_pixels.astype('float32')\n",
    "\t# standardize pixel values across channels (global)\n",
    "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
    "\tface_pixels = (face_pixels - mean) / std\n",
    "\t# transform face into one sample\n",
    "\tsamples = expand_dims(face_pixels, axis=0)\n",
    "\t# make prediction to get embedding\n",
    "\tyhat = model.predict(samples)\n",
    "\treturn yhat[0]\n",
    "\n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "\tfaces = list()\n",
    "\t# enumerate files\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# path\n",
    "\t\tpath = directory + filename\n",
    "\t\t# get face\n",
    "\t\tface = extract_face(path)\n",
    "\t\t# store\n",
    "\t\tfaces.append(face)\n",
    "\treturn faces\n",
    "\n",
    "def live_detection():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3,640) # set Width\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            frame,     \n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,     \n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        try:\n",
    "            x, y, w, h = faces[0]\n",
    "        except:\n",
    "            pass\n",
    "        frame = frame[y:y+h,x:x+w]\n",
    "        \n",
    "        pixels_live = asarray(frame)\n",
    "        embedding_live = get_embedding(facenet_model, pixels_live)\n",
    "        \n",
    "        run(embedding_live, pixels_live, 50)\n",
    "#         cv2.imshow('video',cropFrame)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def run(embedding, image, threshold_percentage):\n",
    "    # prediction for the face\n",
    "    samples = expand_dims(embedding, axis=0)\n",
    "    yhat_class = model.predict(samples)\n",
    "    yhat_prob = model.predict_proba(samples)\n",
    "\n",
    "    out_encoder = LabelEncoder()\n",
    "    out_encoder.fit(labels)\n",
    "\n",
    "    # get name\n",
    "    class_index = yhat_class[0]\n",
    "    class_probability = yhat_prob[0,class_index] * 100\n",
    "    predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "    print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
    "    \n",
    "    if class_probability < threshold_percentage:\n",
    "        predict_names[0] = 'Unknown'\n",
    "    \n",
    "    data = [[predict_names[0],\n",
    "             class_probability,\n",
    "             datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]]\n",
    "    gpi.upload_data(gpi.spreadsheet_id, data)\n",
    "\n",
    "    # plot for fun\n",
    "    pyplot.imshow(image)\n",
    "    title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
    "    pyplot.title(title)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 70\n",
    "test_folder = r'Celebrity Faces Dataset/test/David_Beckham/'\n",
    "test_arrays = load_faces(test_folder)\n",
    "\n",
    "test_embedding = list()\n",
    "for face_pixels in test_arrays:\n",
    "\tembedding = get_embedding(facenet_model, face_pixels)\n",
    "\ttest_embedding.append(embedding)\n",
    "test_embedding = asarray(test_embedding)\n",
    "\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "test_embedding = in_encoder.transform(test_embedding)\n",
    "\n",
    "for embedding, image in zip(test_embedding, test_arrays):\n",
    "    run(embedding, image, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
