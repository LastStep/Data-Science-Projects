{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from gensim.models import Word2Vec \n",
    "\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_url = 'http://www.gutenberg.org/files/2554/2554-0.txt'\n",
    "text = requests.get(text_url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def cleanRawText(text):\n",
    "    #To lower\n",
    "    text = text.lower()\n",
    "    #Removing Unicode Characters\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    #Removing Links\n",
    "    text = re.sub(\"https*\\S+\", \"\", text)\n",
    "    text = re.sub(\"www.*\\S+\", \"\", text)\n",
    "    #Removing Ticks and the Next Character\n",
    "    text = re.sub(\"\\'\\w+\", '', text)\n",
    "    #Removing Punctuation except '.'\n",
    "    text = re.sub(\"[^\\w\\s]\", '', text)\n",
    "    #Removing Numbers and Extra Lines\n",
    "    text = re.sub(\"[\\r\\n\\d\\_]\", ' ', text)\n",
    "    #Removing Extra Spaces\n",
    "    text = re.sub(\" +\", ' ', text)\n",
    "    \n",
    "    #Removing StopWords\n",
    "    text = ' '.join([word for word in text.split(' ') if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cleanRawText(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec([text], min_count=1, size=300, workers=4, window=10, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=10447, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'crime',\n",
       " 'punishment',\n",
       " 'fyodor',\n",
       " 'dostoevsky',\n",
       " 'use',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'cost',\n",
       " 'almost',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'give',\n",
       " 'away',\n",
       " 'reuse',\n",
       " 'terms']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model1.wv.vocab)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gray\\Anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dounia', 0.9983670711517334),\n",
       " ('even', 0.998171865940094),\n",
       " ('one', 0.9981217980384827),\n",
       " ('would', 0.9980551600456238),\n",
       " ('though', 0.9980179071426392),\n",
       " ('room', 0.9979327321052551),\n",
       " ('upon', 0.9978546500205994),\n",
       " ('first', 0.9977613687515259),\n",
       " ('us', 0.9977599382400513),\n",
       " ('time', 0.9976540207862854)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Online Retail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df_text = list(df.Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = ' '.join(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = cleanRawText(df_text)\n",
    "df_text = df_text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Word2Vec([df_text], min_count=1, size=300, workers=4, window=10, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=2047, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
